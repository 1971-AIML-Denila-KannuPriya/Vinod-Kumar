{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119e1906-ad84-4e51-8bd2-f151f5292666",
   "metadata": {},
   "source": [
    "1. Building a Simple Artificial Neural Network (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d89f9a-980f-46ba-b839-c7e0397c752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Question: Build a simple ANN model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(64,)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dfd731-b2c5-4702-bc35-d743176421ab",
   "metadata": {},
   "source": [
    "2. Forward Propagation in a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb54ce3-057c-48fc-aafc-0101709faf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Question: Perform forward propagation with a single input\n",
    "inputs = np.random.randn(1, 64)  # Example input data\n",
    "output = model.predict(inputs)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a63789b-2939-4872-9f2f-779508f7c2e3",
   "metadata": {},
   "source": [
    "3. Configuring Weights, Biases, and Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d3cdb-47e5-481c-926f-32f48bb333f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Dense(32, activation='sigmoid')\n",
    "weights, biases = layer.get_weights()\n",
    "layer.set_weights([np.ones_like(weights), np.zeros_like(biases)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d2ff8-9314-4c19-8d02-3cd33d87e0f3",
   "metadata": {},
   "source": [
    "4. Building a CNN for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b7729f-5a79-496a-aac1-8dd0cc0b41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "# Question: Build a CNN model for image classification\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b19c381-bd93-4bb0-98ee-259b3789dd8b",
   "metadata": {},
   "source": [
    "5. Adding a Convolution Layer with Custom Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f5d404-9923-47e5-9d7c-b4d20616cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.add(Conv2D(64, (5, 5), strides=(2, 2), activation='relu'))\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da5ebe-3728-43bc-816c-b3bfe2b4a75d",
   "metadata": {},
   "source": [
    "6. Training a Neural Network with the fit Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e920e-9d2b-4c1e-864d-f3c995649ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Question: Train a neural network on a simple dataset\n",
    "X_train = np.random.randn(100, 64)\n",
    "y_train = to_categorical(np.random.randint(0, 10, 100))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a21a06b-8bc6-4376-b171-1e7fcca7236c",
   "metadata": {},
   "source": [
    "7. Overfitting Detection and Mitigation with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0459a6-23e5-4353-a1cd-b2fc02619c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# Question: Add a Dropout layer to prevent overfitting\n",
    "model_with_dropout = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(64,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_with_dropout.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09aed9-dc3f-4fea-bc21-59865a20d054",
   "metadata": {},
   "source": [
    "8. Early Stopping and Checkpoint Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0452b0b7-095f-49ce-bffa-49befa849838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Question: Implement early stopping and model checkpoints\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.2, epochs=10, callbacks=[early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f2e95-52c7-4dea-813a-2b7c02349453",
   "metadata": {},
   "source": [
    "9. Using TensorBoard for Monitoring Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ac412-a1d8-4548-bbbf-929ac8c40305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "# Question: Use TensorBoard to visualize training metrics\n",
    "tensorboard = TensorBoard(log_dir='./logs')\n",
    "model.fit(X_train, y_train, epochs=5, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea9869a-661c-46f9-ad1d-26d08de7ed2b",
   "metadata": {},
   "source": [
    "10. Building a Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7be278-8434-4d72-a737-fb2be8fd6dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "# Question: Build a simple RNN model\n",
    "rnn_model = Sequential([\n",
    "    SimpleRNN(50, activation='relu', input_shape=(100, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a51b57-0173-45ec-875f-5563b3baa484",
   "metadata": {},
   "source": [
    "11. Building an LSTM for Sequence Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79504f29-9ff3-4268-922b-cdb9083a2912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Question: Build an LSTM model for sequence prediction\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=(100, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c06c03d-e203-4160-adfc-56b78b59bdd9",
   "metadata": {},
   "source": [
    "12. Backpropagation through Time in RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5adc11-cfd8-47e8-92ac-5d379ee3abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(optimizer='adam', loss='mse')\n",
    "X_seq_train = np.random.randn(100, 100, 1)\n",
    "y_seq_train = np.random.randn(100, 1)\n",
    "\n",
    "rnn_model.fit(X_seq_train, y_seq_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3992abc4-9f17-4579-a5d9-c010e3b0b9dd",
   "metadata": {},
   "source": [
    "13. Word Embeddings with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40640b29-ba9a-4ea2-bf67-d4328c97f41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "# Question: Build a simple model with an Embedding layer\n",
    "embedding_model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=64, input_length=100),\n",
    "    LSTM(128),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b42e11-aae4-4212-876b-cb126b2b909c",
   "metadata": {},
   "source": [
    "14. Training a CNN for Image Classification on CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7054f49-9f37-40f5-8e4a-ba6dd0093285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Question: Load CIFAR-10 dataset and train a CNN\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61408482-cd13-4854-b3f7-8ab6e49919df",
   "metadata": {},
   "source": [
    "15. Adding a MaxPooling Layer to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e53e6-9dc2-486f-aba6-677fd14fa51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3bbbaa-3a65-486c-9055-2a5c15d02114",
   "metadata": {},
   "source": [
    "16. Using GloVe Word Embeddings for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad407fe6-3bba-4aa0-b188-1e787124d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "16. Using GloVe Word Embeddings for NLP\n",
    "python\n",
    "Copy code\n",
    "# Question: Load pre-trained GloVe embeddings for NLP tasks\n",
    "import numpy as np\n",
    "\n",
    "embedding_index = {}\n",
    "with open('glove.6B.100d.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d86792-9c36-4320-bc6a-14f737b6cd29",
   "metadata": {},
   "source": [
    "17. Evaluating Model Performance on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8551500-f280-4b24-8ca1-bb578755c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = cnn_model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b8ac5-6f58-4cc4-ba3a-63633fdea8e0",
   "metadata": {},
   "source": [
    "18. Implementing Custom Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f01ec-5eca-4e2c-80cc-6e825b15c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_activation(x):\n",
    "    return tf.nn.relu(x) - 0.1\n",
    "\n",
    "model_with_custom_act = Sequential([\n",
    "    Dense(64, activation=custom_activation, input_shape=(64,)),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_with_custom_act.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d745a095-91a8-40b7-92d3-e7b19e43ca7f",
   "metadata": {},
   "source": [
    "19. Preparing Data for NLP Tasks Using Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5a567-34a3-4f0a-afe8-9bd0e7d96938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Question: Use Tokenizer to preprocess text data for an NLP task\n",
    "texts = [\"I love deep learning\", \"TensorFlow is great\"]\n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e28725-04ba-42b7-b194-76a18fa1804b",
   "metadata": {},
   "source": [
    "20. Splitting Data into Training, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0508b5-383c-4d3a-aa55-6086de699111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Question: Split data into training, validation, and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
